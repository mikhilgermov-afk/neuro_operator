# app/main.py
# -*- coding: utf-8 -*-
import asyncio
import audioop
import numpy as np
import os
import sys
import struct
import time
import scipy.signal
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger(__name__).info
error_log = logging.getLogger(__name__).error

log("Starting Voice Bot service...")

try:
    from faster_whisper import WhisperModel
    from openai import OpenAI
    from tts_engine import F5TTSWrapper
    import prompts
except ImportError as e:
    error_log(f"CRITICAL ERROR importing libraries: {e}")
    sys.exit(1)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
RTP_IP = "0.0.0.0"
RTP_PORT = 10000
SAMPLE_RATE_TELEPHONY = 8000
SAMPLE_RATE_WHISPER = 16000
CHUNK_SIZE_20MS = 160 

stt_model = None
llm_client = None
tts_engine = None

def load_models():
    global stt_model, llm_client, tts_engine
    log("Loading models...")
    stt_model = WhisperModel("large-v3-turbo", device="cuda", compute_type="float16")
    llm_client = OpenAI(base_url=os.getenv("LLM_API_URL"), api_key="sk-local-key")
    tts_engine = F5TTSWrapper()
    log("All models loaded.")

class CallHandler:
    def __init__(self, transport, addr):
        self.transport = transport
        self.client_addr = addr
        self.history = []
        self.audio_buffer = bytearray()
        self.silence_frames = 0
        self.seq_num = 0
        self.timestamp = 0
        self.ssrc = 123456
        self.is_speaking = False
        self.greeting_sent = False

    async def send_greeting(self):
        if self.greeting_sent: return
        self.greeting_sent = True
        try:
            # –°—Ä–∞–∑—É –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
            log("Generating greeting...")
            sr, audio = tts_engine.generate("–ê–ª–ª–æ, –¥–∞, —è –≤–∞—Å —Å–ª—É—à–∞—é.")
            await self.stream_audio_back(audio, sr)
        except Exception as e:
            error_log(f"Greeting error: {e}")

    def process_incoming_audio(self, data):
        if len(data) <= 12: return
        payload = data[12:]
        try:
            pcm_data = audioop.ulaw2lin(payload, 2)
        except Exception:
            return 

        rms = audioop.rms(pcm_data, 2)
        if rms > 300: 
            self.silence_frames = 0
            self.audio_buffer.extend(pcm_data)
        else:
            self.silence_frames += 1

        if self.silence_frames > 40 and len(self.audio_buffer) > 4000: # –ß—É—Ç—å —É–º–µ–Ω—å—à–∏–ª –ø–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            audio_to_process = self.audio_buffer[:]
            self.audio_buffer = bytearray()
            self.silence_frames = 0
            asyncio.create_task(self.handle_turn(audio_to_process))

    async def handle_turn(self, audio_bytes):
        if not audio_bytes or self.is_speaking: return
        self.is_speaking = True
        
        try:
            # 1. –ë–∞–π—Ç—ã -> Float32
            audio_np = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
            
            # 2. –†–µ—Å–µ–º–ø–ª–∏–Ω–≥
            if len(audio_np) < 100: return
            audio_16k = scipy.signal.resample_poly(audio_np, SAMPLE_RATE_WHISPER, SAMPLE_RATE_TELEPHONY)

            # 3. STT
            segments, _ = stt_model.transcribe(audio_16k, language="ru", beam_size=1)
            user_text = " ".join([s.text for s in segments]).strip()
            
            if len(user_text) < 2:
                self.is_speaking = False
                return

            log(f"üó£Ô∏è User: {user_text}")
            self.history.append({"role": "user", "content": user_text})

            # 4. LLM
            messages = prompts.create_messages(self.history)
            completion = await asyncio.to_thread(
                llm_client.chat.completions.create,
                model="Qwen/Qwen2.5-7B-Instruct", messages=messages, temperature=0.3, max_tokens=100
            )
            bot_text = completion.choices[0].message.content
            
            # –ï—Å–ª–∏ –±–æ—Ç –≤—Å–µ —Ä–∞–≤–Ω–æ –≤—ã–¥–∞–ª –∞–Ω–≥–ª–∏–π—Å–∫–∏–π (–ø–æ–¥—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞), –≤—ã—Ä–µ–∑–∞–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –∏–ª–∏ –ª–æ–≥–∏—Ä—É–µ–º
            log(f"ü§ñ Bot: {bot_text}")
            self.history.append({"role": "assistant", "content": bot_text})

            # 5. TTS
            sr_out, audio_out = await asyncio.to_thread(tts_engine.generate, bot_text)
            
            # 6. –û—Ç–ø—Ä–∞–≤–∫–∞
            await self.stream_audio_back(audio_out, sr_out)

        except Exception as e:
            error_log(f"Error: {e}")
        finally:
            self.is_speaking = False

    async def stream_audio_back(self, audio_np, sr_in):
        if len(audio_np) == 0: 
            error_log("TTS returned empty audio!")
            return

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã (–µ—Å–ª–∏ < 0.5 —Å–µ–∫, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –º—É—Å–æ—Ä)
        duration = len(audio_np) / sr_in
        if duration < 0.5:
             error_log(f"Audio too short ({duration:.2f}s). Skipping to avoid noise.")
             return

        # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        max_val = np.max(np.abs(audio_np))
        if max_val > 0.05:
            audio_np = audio_np / max_val * 0.90
        
        # 2. –†–µ—Å–µ–º–ø–ª–∏–Ω–≥
        gcd = np.gcd(sr_in, SAMPLE_RATE_TELEPHONY)
        up = SAMPLE_RATE_TELEPHONY // gcd
        down = sr_in // gcd
        audio_8k = scipy.signal.resample_poly(audio_np, up, down)
        audio_8k = np.clip(audio_8k, -1.0, 1.0)
        
        # 3. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        audio_int16 = (audio_8k * 32767).astype(np.int16)
        audio_bytes = audio_int16.tobytes()
        audio_ulaw = audioop.lin2ulaw(audio_bytes, 2)

        log(f"üîä Sending {len(audio_ulaw)} bytes ({len(audio_ulaw)/8000:.2f} sec)...")
        
        chunk_size = CHUNK_SIZE_20MS
        packet_count = 0
        start_time = time.perf_counter() # <--- –í–ê–ñ–ù–û: –ó–∞—Å–µ–∫–∞–µ–º –Ω–∞—á–∞–ª–æ

        for i in range(0, len(audio_ulaw), chunk_size):
            chunk = audio_ulaw[i : i + chunk_size]
            if len(chunk) < chunk_size: chunk += b'\xff' * (chunk_size - len(chunk))

            self.seq_num = (self.seq_num + 1) % 65536 
            self.timestamp = (self.timestamp + 160) % 4294967296
            header = struct.pack('!BBHII', 0x80, 0x00, self.seq_num, self.timestamp, self.ssrc)
            
            self.transport.sendto(header + chunk, self.client_addr)
            
            # --- –ö–û–†–†–ï–ö–¶–ò–Ø –î–†–ï–ô–§–ê (Drift Correction) ---
            # –í–º–µ—Å—Ç–æ sleep(0.02) –º—ã —Å–ø–∏–º —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ, —á—Ç–æ–±—ã –ø–æ–ø–∞—Å—Ç—å –≤ —Å–ª–µ–¥—É—é—â–∏–π —Ç–∞–∫—Ç
            packet_count += 1
            expected_time = start_time + (packet_count * 0.02)
            delay = expected_time - time.perf_counter()
            if delay > 0:
                await asyncio.sleep(delay)
            # ------------------------------------------

class RTPProtocol(asyncio.DatagramProtocol):
    def __init__(self):
        self.calls = {}
        self.transport = None
    def connection_made(self, transport):
        self.transport = transport
        log(f"‚úÖ READY on {RTP_IP}:{RTP_PORT}")
    def datagram_received(self, data, addr):
        if addr not in self.calls:
            self.calls[addr] = CallHandler(self.transport, addr)
            asyncio.create_task(self.calls[addr].send_greeting())
        self.calls[addr].process_incoming_audio(data)

async def main():
    load_models()
    loop = asyncio.get_running_loop()
    transport, protocol = await loop.create_datagram_endpoint(lambda: RTPProtocol(), local_addr=(RTP_IP, RTP_PORT))
    try: await asyncio.Future()
    except asyncio.CancelledError: pass
    finally: transport.close()

if __name__ == "__main__":
    asyncio.run(main())
