import asyncio
import audioop
import numpy as np
import os
import sys
import struct
import time
import scipy.signal
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
log = logging.getLogger(__name__).info
error_log = logging.getLogger(__name__).error

log("Starting Voice Bot service...")

try:
    log("Importing libraries...")
    from faster_whisper import WhisperModel
    from openai import OpenAI
    from tts_engine import F5TTSWrapper
    import prompts
    log("Libraries imported.")
except ImportError as e:
    error_log(f"CRITICAL ERROR importing libraries: {e}")
    sys.exit(1)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
RTP_IP = "0.0.0.0"
RTP_PORT = 10000
SAMPLE_RATE_TELEPHONY = 8000
SAMPLE_RATE_WHISPER = 16000 # Whisper –æ–∂–∏–¥–∞–µ—Ç 16k
CHUNK_SIZE_20MS = 160 

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
stt_model = None
llm_client = None
tts_engine = None

def load_models():
    global stt_model, llm_client, tts_engine
    
    log("1/3 Loading Whisper (STT)...")
    # medium –∏–ª–∏ large-v3-turbo - –≤—ã–±–∏—Ä–∞–π –ø–æ –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏
    stt_model = WhisperModel("large-v3-turbo", device="cuda", compute_type="float16")
    log("   > Whisper loaded.")

    log("2/3 Connecting to LLM Client...")
    llm_client = OpenAI(base_url=os.getenv("LLM_API_URL"), api_key="sk-local-key")
    log("   > LLM Client configured.")

    log("3/3 Loading F5-TTS (Voice)...")
    tts_engine = F5TTSWrapper()
    log("   > F5-TTS loaded.")

class CallHandler:
    def __init__(self, transport, addr):
        self.transport = transport
        self.client_addr = addr
        self.history = []
        self.audio_buffer = bytearray()
        self.silence_frames = 0
        
        # RTP State
        self.seq_num = 0
        self.timestamp = 0
        self.ssrc = 123456
        
        self.is_speaking = False
        self.greeting_sent = False

    async def send_greeting(self):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∑–≤–æ–Ω–∫–∞"""
        if self.greeting_sent: return
        self.greeting_sent = True
        
        greeting_text = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø —Å–ª—É—à–∞—é."
        log(f"Ì†ΩÌ±ã Sending greeting: {greeting_text}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–µ–π–∫–æ–≤—ã–π "User" —Ö–æ–¥, —á—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ü–µ–ø–æ—á–∫—É, 
        # –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º TTS –Ω–∞–ø—Ä—è–º—É—é. –õ—É—á—à–µ –Ω–∞–ø—Ä—è–º—É—é.
        try:
            sr, audio = tts_engine.generate(greeting_text)
            await self.stream_audio_back(audio, sr)
        except Exception as e:
            error_log(f"Greeting failed: {e}")

    def process_incoming_audio(self, data):
        # –£–¥–∞–ª—è–µ–º RTP –∑–∞–≥–æ–ª–æ–≤–æ–∫ (12 –±–∞–π—Ç)
        if len(data) <= 12: return
        payload = data[12:]
        
        try:
            # ulaw -> pcm16
            pcm_data = audioop.ulaw2lin(payload, 2)
        except Exception:
            return 

        # VAD (–¥–µ—Ç–µ–∫—Ç–æ—Ä –≥–æ–ª–æ—Å–∞ –ø–æ —ç–Ω–µ—Ä–≥–∏–∏)
        rms = audioop.rms(pcm_data, 2)
        
        # –ü–æ—Ä–æ–≥ (–ø–æ–¥–±–∏—Ä–∞—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–æ, 100-300 –æ–±—ã—á–Ω–æ –æ–∫ –¥–ª—è —Ç–∏—à–∏–Ω—ã)
        if rms > 150: 
            self.silence_frames = 0
            self.audio_buffer.extend(pcm_data)
        else:
            self.silence_frames += 1

        # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–∏ –±—É—Ñ–µ—Ä –∏ –Ω–∞—Å—Ç—É–ø–∏–ª–∞ —Ç–∏—à–∏–Ω–∞ (0.6 —Å–µ–∫)
        if self.silence_frames > 30 and len(self.audio_buffer) > 4000:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ—á–∏—Ç—å –ø—Ä–∏–µ–º –ø–∞–∫–µ—Ç–æ–≤
            asyncio.create_task(self.handle_turn())
            self.audio_buffer = bytearray()
            self.silence_frames = 0

    async def handle_turn(self):
        if self.is_speaking: return # –ù–µ –ø–µ—Ä–µ–±–∏–≤–∞–µ–º —Å–∞–º–∏ —Å–µ–±—è –ø–æ–∫–∞ (–ø—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞)
        
        buffer_len = len(self.audio_buffer)
        log(f"--- Processing Turn (Buffer: {buffer_len} bytes) ---")
        self.is_speaking = True
        
        try:
            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ –¥–ª—è Whisper
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bytearray -> numpy float32
            audio_np_8k = np.frombuffer(self.audio_buffer, dtype=np.int16).astype(np.float32) / 32768.0
            
            # --- –í–ê–ñ–ù–û: –†–ï–°–ï–ú–ü–õ–ò–ù–ì 8k -> 16k ---
            # Whisper —Ç—Ä–µ–±—É–µ—Ç 16kHz. 
            num_samples_16k = int(len(audio_np_8k) * SAMPLE_RATE_WHISPER / SAMPLE_RATE_TELEPHONY)
            audio_np_16k = scipy.signal.resample(audio_np_8k, num_samples_16k)
            # -----------------------------------

            # 2. Whisper
            segments, _ = stt_model.transcribe(audio_np_16k, language="ru", beam_size=1)
            user_text = " ".join([s.text for s in segments]).strip()
            
            if not user_text or len(user_text) < 2:
                log("   > Silence/Noise detected (No text)")
                self.is_speaking = False
                return

            log(f"Ì†ΩÌ∑£Ô∏è User: {user_text}")
            self.history.append({"role": "user", "content": user_text})

            # 3. LLM
            messages = prompts.create_messages(self.history)
            log("   > Asking LLM...")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º to_thread, —á—Ç–æ–±—ã requests –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞–ª event loop
            completion = await asyncio.to_thread(
                llm_client.chat.completions.create,
                model="Qwen/Qwen2.5-7B-Instruct",
                messages=messages,
                temperature=0.6,
                max_tokens=150
            )
            
            bot_text = completion.choices[0].message.content
            log(f"Ì†æÌ¥ñ Bot: {bot_text}")
            self.history.append({"role": "assistant", "content": bot_text})

            # 4. TTS
            log("   > Generating Audio...")
            # to_thread –¥–ª—è —Ç—è–∂–µ–ª–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            sr_out, audio_out = await asyncio.to_thread(tts_engine.generate, bot_text)
            
            # 5. –û—Ç–ø—Ä–∞–≤–∫–∞
            await self.stream_audio_back(audio_out, sr_out)
            
        except Exception as e:
            error_log(f"Error processing turn: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.is_speaking = False

    async def stream_audio_back(self, audio_float, sr_in):
        if len(audio_float) == 0: return

        # –†–µ—Å–µ–º–ø–ª–∏–Ω–≥ –æ–±—Ä–∞—Ç–Ω–æ –≤ 8k –¥–ª—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞
        num_samples_8k = int(len(audio_float) * SAMPLE_RATE_TELEPHONY / sr_in)
        audio_8k = scipy.signal.resample(audio_float, num_samples_8k)
        
        # float32 -> int16 -> ulaw
        audio_int16 = (audio_8k * 32767).astype(np.int16)
        audio_bytes = audio_int16.tobytes()
        audio_ulaw = audioop.lin2ulaw(audio_bytes, 2)

        chunk_size = CHUNK_SIZE_20MS
        log(f"Ì†ΩÌ¥ä Sending audio back ({len(audio_ulaw)} bytes)...")
        
        for i in range(0, len(audio_ulaw), chunk_size):
            chunk = audio_ulaw[i : i + chunk_size]
            if len(chunk) < chunk_size:
                chunk += b'\xff' * (chunk_size - len(chunk)) # Silence padding

            # RTP Header
            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω wrap seq (65536) –∏ timestamp (2^32)
            self.seq_num = (self.seq_num + 1) % 65536 
            self.timestamp = (self.timestamp + 160) % 4294967296
            
            header = struct.pack('!BBHII', 0x80, 0x00, self.seq_num, self.timestamp, self.ssrc)
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ asyncio transport (–Ω–µ–±–ª–æ–∫–∏—Ä—É—é—â–∞—è)
            self.transport.sendto(header + chunk, self.client_addr)
            
            # –¢–∞–π–º–∏–Ω–≥ 20–º—Å
            await asyncio.sleep(0.0195) 

class RTPProtocol(asyncio.DatagramProtocol):
    def __init__(self):
        self.calls = {} # addr -> CallHandler
        self.transport = None

    def connection_made(self, transport):
        self.transport = transport
        log(f"‚úÖ SYSTEM READY. Listening RTP on {RTP_IP}:{RTP_PORT}")

    def datagram_received(self, data, addr):
        if addr not in self.calls:
            log(f"New call from {addr}")
            handler = CallHandler(self.transport, addr)
            self.calls[addr] = handler
            # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –ø–∞–∫–µ—Ç–µ
            asyncio.create_task(handler.send_greeting())
        
        # –ü–µ—Ä–µ–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        self.calls[addr].process_incoming_audio(data)

async def main():
    load_models()
    
    loop = asyncio.get_running_loop()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º UDP —Å–µ—Ä–≤–µ—Ä —á–µ—Ä–µ–∑ DatagramProtocol (Native AsyncIO)
    transport, protocol = await loop.create_datagram_endpoint(
        lambda: RTPProtocol(),
        local_addr=(RTP_IP, RTP_PORT)
    )

    try:
        # –î–µ—Ä–∂–∏–º —Å–µ—Ä–≤–∏—Å –∂–∏–≤—ã–º
        await asyncio.Future()
    except asyncio.CancelledError:
        pass
    finally:
        transport.close()

if __name__ == "__main__":
    asyncio.run(main())